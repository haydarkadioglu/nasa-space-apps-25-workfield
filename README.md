# ğŸŒŒ NASA Space Apps Challenge 2025 - Workfield

**Challenge: "A World Away: Hunting for Exoplanets with AI"**

*Developed by **Kozmik Zihinler** (Cosmic Minds) Team*

---

## ğŸ¯ Project Overview

This repository contains the complete development workfield for our NASA Space Apps Challenge 2025 submission. We've built an AI-powered exoplanet classification system that analyzes data from NASA's major space missions (Kepler, K2, and TESS) to identify and classify exoplanet candidates.

## ğŸš€ Final Deployment

**Live Demo**: [NASA Exoplanet Hunter](https://github.com/haydarkadioglu/exoplanet-hunting)

The production-ready application is deployed in a separate repository for clean distribution and easy access.

## ğŸ“ Repository Structure

```
nasa-space-apps-workfield/
â”œâ”€â”€ ğŸ“‚ archive/                     # Original raw datasets
â”‚   â”œâ”€â”€ Astro_Flux_Data.csv
â”‚   â”œâ”€â”€ Astro_Time_Data.csv
â”‚   â””â”€â”€ features_dataset.csv
â”‚
â”œâ”€â”€ ğŸ“‚ k2/                          # K2 Mission Data Processing
â”‚   â”œâ”€â”€ k2.csv                      # Processed K2 dataset
â”‚   â”œâ”€â”€ preprocess-k2-vol-1.ipynb  # Data preprocessing notebook
â”‚   â”œâ”€â”€ train_v1.ipynb             # Model training notebook
â”‚   â”œâ”€â”€ ğŸ“‚ vol1/                   # Training data volume 1
â”‚   â”œâ”€â”€ ğŸ“‚ vol1_3class/            # 3-class classification data
â”‚   â””â”€â”€ info-txt                   # Dataset information
â”‚
â”œâ”€â”€ ğŸ“‚ kepler/                      # Kepler Mission Data Processing
â”‚   â”œâ”€â”€ kepler.csv                  # Processed Kepler dataset
â”‚   â”œâ”€â”€ preprocess_kepler.ipynb    # Data preprocessing notebook
â”‚   â”œâ”€â”€ train_v1.ipynb             # Model training notebook
â”‚   â”œâ”€â”€ ğŸ“‚ kepler_3class/          # 3-class classification data
â”‚   â”œâ”€â”€ ğŸ“‚ kepler_models/          # Trained model artifacts
â”‚   â””â”€â”€ info.txt                   # Dataset information
â”‚
â”œâ”€â”€ ğŸ“‚ tess/                        # TESS Mission Data Processing
â”‚   â”œâ”€â”€ TOI.csv                     # TESS Objects of Interest dataset
â”‚   â”œâ”€â”€ TIC_IDs.csv                # TESS Input Catalog IDs
â”‚   â”œâ”€â”€ preprocess_tess.ipynb      # Data preprocessing notebook
â”‚   â”œâ”€â”€ train_v2.ipynb             # Model training v2
â”‚   â”œâ”€â”€ train_v3.ipynb             # Model training v3
â”‚   â”œâ”€â”€ train_v4.ipynb             # Model training v4
â”‚   â”œâ”€â”€ train_v5.ipynb             # Model training v5
â”‚   â”œâ”€â”€ v6.ipynb                   # Final model version
â”‚   â”œâ”€â”€ train_v4_final_comparison.py # Model comparison script
â”‚   â”œâ”€â”€ ğŸ“‚ tess_3class/            # 3-class classification data
â”‚   â”œâ”€â”€ ğŸ“‚ tess_models/            # Trained model artifacts
â”‚   â”œâ”€â”€ ğŸ“‚ autogluon_models/       # AutoGluon experiment results
â”‚   â”œâ”€â”€ ğŸ“‚ vol2/ vol3/ vol4/       # Training data volumes
â”‚   â”œâ”€â”€ ğŸ“‚ cache/                  # Cached preprocessing results
â”‚   â”œâ”€â”€ ğŸ“‚ playground/             # Experimental notebooks
â”‚   â”œâ”€â”€ toi_feature_mapping.json   # Feature mapping configuration
â”‚   â”œâ”€â”€ toi_pipeline_metadata.json # Pipeline metadata
â”‚   â”œâ”€â”€ toi_preprocessing_pipeline.joblib # Preprocessing pipeline
â”‚   â””â”€â”€ info.txt                   # Dataset information
â”‚
â”œâ”€â”€ ğŸ“‚ main/                        # Final model artifacts
â”‚   â”œâ”€â”€ ğŸ“‚ k2/                     # K2 production models
â”‚   â”œâ”€â”€ ğŸ“‚ kepler/                 # Kepler production models
â”‚   â””â”€â”€ ğŸ“‚ toi/                    # TESS production models
â”‚
â”œâ”€â”€ ğŸ“‚ csa/                         # Canadian Space Agency data
â”‚   â”œâ”€â”€ download.py                 # Data download script
â”‚   â””â”€â”€ ğŸ“‚ data/                   # FITS data files
â”‚
â”œâ”€â”€ ğŸ“‚ exoplanet-hunting/          # Frontend Application
â”‚   â”œâ”€â”€ ğŸ“‚ frontend/               # Web application
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ src/                # TypeScript source code
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ public/             # Static assets & ONNX models
â”‚   â”‚   â”œâ”€â”€ package.json           # Dependencies
â”‚   â”‚   â”œâ”€â”€ vite.config.ts         # Build configuration
â”‚   â”‚   â””â”€â”€ index.html             # Main HTML file
â”‚   â””â”€â”€ README.md                  # Application documentation
â”‚
â”œâ”€â”€ ğŸ”§ Utility Scripts
â”‚   â”œâ”€â”€ convert_to_onnx.py         # Model conversion to ONNX format
â”‚   â”œâ”€â”€ convert_kepler_special.py  # Special Kepler data conversion
â”‚   â”œâ”€â”€ tkinter_app.py             # Desktop GUI application
â”‚   â””â”€â”€ dataset_comparison_analysis.ipynb # Dataset analysis
â”‚
â”œâ”€â”€ ğŸ“Š Data Files
â”‚   â”œâ”€â”€ tois.csv                   # TESS Objects of Interest
â”‚   â”œâ”€â”€ archive.zip                # Compressed archive data
â”‚   â””â”€â”€ ğŸ“‚ flux_data/              # Light curve flux data
â”‚
â””â”€â”€ ğŸ“‹ Documentation
    â”œâ”€â”€ README.md                   # This file
    â””â”€â”€ ONNX_CONVERSION_SUMMARY.md  # ONNX conversion documentation
```

## ğŸ› ï¸ Technical Architecture

### Data Processing Pipeline

1. **Data Ingestion**: Raw astronomical data from NASA archives
2. **Feature Engineering**: Extract meaningful parameters from light curves
3. **Preprocessing**: Normalization, cleaning, and feature selection
4. **Model Training**: Machine learning model development
5. **Model Conversion**: ONNX format for web deployment
6. **Web Integration**: TypeScript frontend with ONNX Runtime

### Machine Learning Models

| Dataset | Algorithm | Features | Accuracy | Status |
|---------|-----------|----------|----------|---------|
| **K2** | Gradient Boosting | 145 | 97.00% | âœ… Production |
| **Kepler** | LightGBM | 106 | 85.36% | âœ… Production |
| **TESS** | Random Forest | 43 | 89.94% | âœ… Production |

### Technology Stack

#### Backend & ML
- **Python 3.8+**: Core development language
- **Scikit-learn**: Machine learning algorithms
- **LightGBM**: Gradient boosting framework
- **AutoGluon**: Automated ML experiments
- **ONNX**: Model serialization and deployment
- **Pandas/NumPy**: Data manipulation
- **Jupyter**: Interactive development

#### Frontend
- **TypeScript**: Type-safe JavaScript development
- **Vite**: Modern build tool and dev server
- **ONNX Runtime Web**: Client-side model inference
- **HTML5/CSS3**: Modern web standards
- **WebAssembly**: High-performance computation

#### Data Sources
- **NASA Exoplanet Archive**: Kepler and K2 mission data
- **MAST Portal**: TESS mission data and TOI catalog
- **Canadian Space Agency**: NEO surveillance data

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+ with Jupyter
- Node.js 16+ for frontend development
- Git for version control

### Setting Up Development Environment

1. **Clone the repository**:
```bash
git clone https://github.com/haydarkadioglu/nasa-space-apps-25-workfield.git
cd nasa-space-apps-25-workfield
```

2. **Set up Python environment**:
```bash
pip install jupyter pandas numpy scikit-learn lightgbm onnx onnxruntime
```

3. **Explore the data processing**:
```bash
# Start with K2 data processing
jupyter notebook k2/preprocess-k2-vol-1.ipynb

# Or explore TESS data
jupyter notebook tess/preprocess_tess.ipynb
```

4. **Run the web application**:
```bash
cd exoplanet-hunting/frontend
npm install
npm run dev
```

## ğŸ“Š Development Workflow

### 1. Data Processing Phase
- **Notebooks**: `*/preprocess_*.ipynb` - Data cleaning and feature engineering
- **Training**: `*/train_*.ipynb` - Model development and evaluation
- **Evaluation**: Confusion matrices and performance metrics

### 2. Model Development Phase
- **Experimentation**: Multiple algorithm testing (Random Forest, LightGBM, etc.)
- **Hyperparameter Tuning**: Grid search and cross-validation
- **Feature Selection**: Importance analysis and dimensionality reduction

### 3. Production Phase
- **ONNX Conversion**: `convert_to_onnx.py` - Model serialization
- **Web Integration**: TypeScript frontend development
- **Performance Optimization**: Client-side inference optimization

## ğŸ”¬ Scientific Methodology

### Classification Categories
- **ğŸ” Candidate**: Transit-like signals requiring verification
- **âœ… Confirmed**: Validated exoplanets with high confidence
- **âŒ False Positive**: Stellar activity or instrumental artifacts

### Feature Engineering
- **Kepler**: Orbital parameters, stellar characteristics, signal properties
- **K2**: Extended mission features with advanced noise filtering
- **TESS**: TOI catalog parameters optimized for all-sky survey data

### Model Validation
- **Cross-validation**: 5-fold stratified validation
- **Performance Metrics**: Accuracy, Precision, Recall, F1-Score
- **Confusion Analysis**: Detailed error analysis and bias detection

## ğŸ† Team: Kozmik Zihinler (Cosmic Minds)

A passionate team of developers and data scientists dedicated to advancing exoplanet discovery through artificial intelligence for the **2025 NASA Space Apps Challenge**.

## ğŸ“ˆ Results and Impact

Our AI models demonstrate state-of-the-art performance in exoplanet classification:
- **High Accuracy**: Up to 97% classification accuracy
- **Real-time Inference**: Sub-second prediction times
- **Web Accessibility**: Browser-based tool for researchers worldwide
- **Multi-mission Support**: Unified interface for diverse datasets

## ğŸ”— Links

- **ğŸŒŸ Live Application**: [exoplanet-hunting](https://github.com/haydarkadioglu/exoplanet-hunting)
- **ğŸ“Š NASA Exoplanet Archive**: [exoplanetarchive.ipac.caltech.edu](https://exoplanetarchive.ipac.caltech.edu/)
- **ğŸ”­ TESS Mission**: [tess.mit.edu](https://tess.mit.edu/)
- **ğŸ›°ï¸ Kepler Mission**: [www.nasa.gov/kepler](https://www.nasa.gov/kepler)

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

We welcome contributions! Please feel free to submit pull requests, report issues, or suggest improvements.

---

*"Advancing the frontier of exoplanet discovery through the power of artificial intelligence."*  
**- Kozmik Zihinler (Cosmic Minds) Team**
